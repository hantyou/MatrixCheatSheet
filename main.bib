@article{Candes2008,
	abstract = {This chapter provides an overview of compressive sampling (CS), introducing both the signal acquisition and reconstruction protocols. A novel, computationally light, overlapped window reconstruction algorithm is introduced to circumvent the problem of edge artifacts in conventional CS reconstruction. The proposed approach is shown to reduce the central processing unit (CPU) execution time by a factor of 2.4 without degradation of reconstruction accuracy compared to a traditional longer window reconstruction approach for photoplethysmogram (PPG) signals. Finally, this chapter also presents the state-of-the-art CS implementations for biosignal acquisition and processing.},
	author = {Candes, E.J. and Wakin, M.B.},
	doi = {10.1109/MSP.2007.914731},
	file = {:D\:/Mendeley Working Foler/IEEE Signal Processing Magazine/2008/Candes, Wakin - 2008 - An Introduction To Compressive Sampling.pdf:pdf},
	issn = {1053-5888},
	journal = {IEEE Signal Processing Magazine},
	mendeley-groups = {PhD - 1st Year/compressed sensing},
	month = {mar},
	number = {2},
	pages = {21--30},
	title = {{An Introduction To Compressive Sampling}},
	url = {http://ieeexplore.ieee.org/document/4472240/},
	volume = {25},
	year = {2008}
}


@article{Choi2017,
	abstract = {As a paradigm to recover the sparse signal from a small set of linear measurements, compressed sensing (CS) has stimulated a great deal of interest in recent years. In order to apply the CS techniques to wireless communication systems, there are a number of things to know and also several issues to be considered. However, it is not easy to grasp simple and easy answers to the issues raised while carrying out research on CS. The main purpose of this paper is to provide essential knowledge and useful tips and tricks that wireless communication researchers need to know when designing CS-based wireless systems. First, we present an overview of the CS technique, including basic setup, sparse recovery algorithm, and performance guarantee. Then, we describe three distinct subproblems of CS, viz., sparse estimation, support identification, and sparse detection, with various wireless communication applications. We also address main issues encountered in the design of CS-based wireless communication systems. These include potentials and limitations of CS techniques, useful tips that one should be aware of, subtle points that one should pay attention to, and some prior knowledge to achieve better performance. Our hope is that this paper will be a useful guide for wireless communication researchers and even non-experts to get the gist of CS techniques.},
	archivePrefix = {arXiv},
	arxivId = {1511.08746},
	author = {Choi, Jun Won and Shim, Byonghyo and Ding, Yacong and Rao, Bhaskar and Kim, Dong In},
	doi = {10.1109/COMST.2017.2664421},
	eprint = {1511.08746},
	file = {:D\:/Mendeley Working Foler/IEEE Communications Surveys and Tutorials/2017/Choi et al. - 2017 - Compressed Sensing for Wireless Communications Useful Tips and Tricks.pdf:pdf},
	issn = {1553877X},
	journal = {IEEE Communications Surveys and Tutorials},
	keywords = {Compressed sensing,greedy algorithm,l-norm,performance guarantee,sparse signal,underdetermined systems,wireless communication systems},
	mendeley-groups = {PhD - 1st Year/compressed sensing},
	number = {3},
	pages = {1527--1550},
	title = {{Compressed Sensing for Wireless Communications: Useful Tips and Tricks}},
	volume = {19},
	year = {2017}
}

@article{Donoho2006,
	abstract = {Suppose is x an unknown vector in Rm(a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m Thus, certain natural classes of images with m pixels need only n = 0(m1/4 log5/2 (m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor) - so the coefficients belong to ℓp ball for 0 < p ≤ 1. The N important coefficients in that expansion allow reconstruction with ℓ2 error O(N1/2-1/p). It is possible to design n = (N log (m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N most important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program - Basis Pursuit in signal processing. The nonadaptive measurements have the character of "random" linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel'fand n-widths of ℓp balls in high-dimensional Euclidean space in the case 0 < p ≤ 1, and give a criterion identifying near-optimal subspaces for Gel'fand n-widths. We show that "most" subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces. {\textcopyright} 2006 IEEE.},
	author = {Donoho, David L.},
	doi = {10.1109/TIT.2006.871582},
	file = {:D\:/Mendeley Working Foler/IEEE Transactions on Information Theory/2006/Donoho - 2006 - Compressed sensing.pdf:pdf},
	issn = {00189448},
	journal = {IEEE Transactions on Information Theory},
	keywords = {Adaptive sampling,Almost-spherical sections of Banach spaces,Basis Pursuit,Eigenvalues of random matrices,Gel'fand n-widths,Information-based complexity,Integrated sensing and processing,Minimum ℓ1-norm decomposition,Optimal recovery,Quotient-of-a-Subspace theorem,Sparse solution of linear equations},
	mendeley-groups = {PhD - 1st Year/compressed sensing},
	number = {4},
	pages = {1289--1306},
	title = {{Compressed sensing}},
	volume = {52},
	year = {2006}
}

@article{Tropp2007,
	abstract = {This paper demonstrates theoretically and empirically that a greedy algorithm called orthogonal matching pursuit (OMP) can reliably recover a signal with m nonzero entries in dimension d given O(m ln d) random linear measurements of that signal. This is a massive improvement over previous results, which require O(m2) measurements. The new results for OMP are comparable with recent results for another approach called basis pursuit (BP). In some settings, the OMP algorithm is faster and easier to implement, so it is an attractive alternative to BP for signal recovery problems. {\textcopyright} 2007 IEEE.},
	author = {Tropp, Joel A. and Gilbert, Anna C.},
	doi = {10.1109/TIT.2007.909108},
	file = {:D\:/Mendeley Working Foler/IEEE Transactions on Information Theory/2007/Tropp, Gilbert - 2007 - Signal Recovery From Random Measurements Via Orthogonal Matching Pursuit.pdf:pdf},
	issn = {0018-9448},
	journal = {IEEE Transactions on Information Theory},
	keywords = {Algorithms,Approximation,Basis pursuit,Compressed sensing,Group testing,Orthogonal matching pursuit,Signal recovery,Sparse approximation},
	mendeley-groups = {PhD - 1st Year/compressed sensing},
	month = {dec},
	number = {12},
	pages = {4655--4666},
	title = {{Signal Recovery From Random Measurements Via Orthogonal Matching Pursuit}},
	url = {http://ieeexplore.ieee.org/document/4385788/},
	volume = {53},
	year = {2007}
}
@article{Baraniuk2010,
author = {Baraniuk, Richard G and Cevher, Volkan and Duarte, Marco F},
file = {:D\:/Mendeley Working Foler/Unknown/2010/Baraniuk, Cevher, Duarte - 2010 - Model-Based Compressive Sensing.pdf:pdf},
isbn = {9550071030},
mendeley-groups = {PhD - 1st Year/compressed sensing/Block Sparsity},
number = {4},
pages = {1982--2001},
title = {{Model-Based Compressive Sensing}},
volume = {56},
year = {2010}
}
@article{Eldar2009,
abstract = {Traditional sampling theories consider the problem of reconstructing an unknown signal $\chi$ from a series of samples. A prevalent assumption which often guarantees recovery from the given measurements is that $\chi$ lies in a known subspace. Recently, there has been growing interest in nonlinear but structured signal models, in which $\chi$ lies in a union of subspaces. In this paper, we develop a general framework for robust and efficient recovery of such signals from a given set of samples. More specifically, we treat the case in which $\chi$ lies in a sum of $\kappa$ subspaces, chosen from a larger set of m possibilities. The samples are modeled as inner products with an arbitrary set of sampling functions. To derive an efficient and robust recovery algorithm, we show that our problem can be formulated as that of recovering a block-sparse vector whose nonzero elements appear in fixed blocks. We then propose a mixed ℓ2/ℓ1 program for block sparse recovery. Our main result is an equivalence condition under which the proposed convex algorithm is guaranteed to recover the original signal. This result relies on the notion of block restricted isometry property (RIP), which is a generalization of the standard RIP used extensively in the context of compressed sensing. Based on RIP, we also prove stability of our approach in the presence of noise and modeling errors. A special case of our framework is that of recovering multiple measurement vectors (MMV) that share a joint sparsity pattern. Adapting our results to this context leads to new MMV recovery methods as well as equivalence conditions under which the entire set can be determined efficiently. {\textcopyright} 2009 IEEE.},
archivePrefix = {arXiv},
arxivId = {0807.4581},
author = {Eldar, Yonina C. and Mishali, Moshe},
doi = {10.1109/TIT.2009.2030471},
eprint = {0807.4581},
file = {:D\:/Mendeley Working Foler/IEEE Transactions on Information Theory/2009/Eldar, Mishali - 2009 - Robust recovery of signals from a structured union of subspaces.pdf:pdf},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Block restricted isometry property,Block sparsity,Compressed sensing,Mixed-norm recovery,Multiple measurement vectors (MMV),Union of linear subspaces},
mendeley-groups = {PhD - 1st Year/compressed sensing/Block Sparsity},
number = {11},
pages = {5302--5316},
title = {{Robust recovery of signals from a structured union of subspaces}},
volume = {55},
year = {2009}
}
@article{Huang2011,
abstract = {This paper investigates a learning formulation called structured sparsity, which is a natural extension of the standard sparsity concept in statistical learning and compressive sensing. By allowing arbitrary structures on the feature set, this concept generalizes the group sparsity idea that has become popular in recent years. A general theory is developed for learning with structured sparsity, based on the notion of coding complexity associated with the structure. It is shown that if the coding complexity of the target signal is small, then one can achieve improved performance by using coding complexity regularization methods, which generalize the standard sparse regularization. Moreover, a structured greedy algorithm is proposed to efficiently solve the structured sparsity problem. It is shown that the greedy algorithm approximately solves the coding complexity optimization problem under appropriate conditions. Experiments are included to demonstrate the advantage of structured sparsity over standard sparsity on some real applications. {\textcopyright} 2011 Junzhou Huang, Tong Zhang and Dimitris Metaxas.},
archivePrefix = {arXiv},
arxivId = {0903.3002},
author = {Huang, Junzhou and Zhang, Tong and Metaxas, Dimitris},
eprint = {0903.3002},
file = {:D\:/Mendeley Working Foler/Journal of Machine Learning Research/2011/Huang, Zhang, Metaxas - 2011 - Learning with structured sparsity.pdf:pdf},
issn = {15324435},
journal = {Journal of Machine Learning Research},
keywords = {Compressive sensing,Feature selection,Graph sparsity,Group sparsity,Sparse learning,Standard sparsity,Structured sparsity,Tree sparsity},
mendeley-groups = {PhD - 1st Year/compressed sensing/Block Sparsity},
pages = {3371--3412},
title = {{Learning with structured sparsity}},
volume = {12},
year = {2011}
}
@article{Dabov2007,
abstract = {We propose an effective video denoising method based on highly sparse signal representation in local 3D transform domain. A noisy video is processed in blockwise manner and for each processed block we form a 3D data array that we call "group" by stacking together blocks found similar to the currently processed one. This grouping is realized as a spatio-temporal predictive-search block-matching, similar to techniques used for motion estimation. Each formed 3D group is filtered by a 3D transform-domain shrinkage (hard-thresholding and Wiener filtering), the result of which are estimates of all grouped blocks. This filtering - that we term "collaborative filtering"- exploits the correlation between grouped blocks and the corresponding highly sparse representation of the true signal in the transform domain. Since, in general, the obtained block estimates are mutually overlapping, we aggregate them by a weighted average in order to form a non-redundant estimate of the video. Significant improvement of this approach is achieved by using a two-step algorithm where an intermediate estimate is produced by grouping and collaborative hard-thresholding and then used both for improving the grouping and for applying collaborative empirical Wiener filtering. We develop an efficient realization of this video denoising algorithm. The experimental results show that at reasonable computational cost it achieves state-of-the-art denoising performance in terms of both peak signal-to-noise ratio and subjective visual quality. {\textcopyright} 2007 EURASIP.},
author = {Dabov, Kostadin and Foi, Alessandro and Egiazarian, Karen},
file = {:D\:/Mendeley Working Foler/European Signal Processing Conference/2007/Dabov, Foi, Egiazarian - 2007 - Video denoising by sparse 3D transform-domain collaborative filtering.pdf:pdf},
isbn = {9788392134022},
issn = {22195491},
journal = {European Signal Processing Conference},
mendeley-groups = {PhD - 1st Year/compressed sensing/Block Sparsity},
number = {8},
pages = {145--149},
title = {{Video denoising by sparse 3D transform-domain collaborative filtering}},
volume = {16},
year = {2007}
}
@article{Eldar2010,
abstract = {We consider efficient methods for the recovery of block-sparse signalsi.e., sparse signals that have nonzero entries occurring in clustersfrom an underdetermined system of linear equations. An uncertainty relation for block-sparse signals is derived, based on a block-coherence measure, which we introduce. We then show that a block-version of the orthogonal matching pursuit algorithm recovers block k-sparse signals in no more than k steps if the block-coherence is sufficiently small. The same condition on block-coherence is shown to guarantee successful recovery through a mixed l2/l 1-optimization approach. This complements previous recovery results for the block-sparse case which relied on small block-restricted isometry constants. The significance of the results presented in this paper lies in the fact that making explicit use of block-sparsity can provably yield better reconstruction properties than treating the signal as being sparse in the conventional sense, thereby ignoring the additional structure in the problem. {\textcopyright} 2010 IEEE.},
author = {Eldar, Yonina C. and Kuppinger, Patrick and B{\"{o}}lcskei, Helmut},
doi = {10.1109/TSP.2010.2044837},
file = {:D\:/Mendeley Working Foler/IEEE Transactions on Signal Processing/2010/Eldar, Kuppinger, B{\"{o}}lcskei - 2010 - Block-sparse signals Uncertainty relations and efficient recovery.pdf:pdf},
issn = {1053587X},
journal = {IEEE Transactions on Signal Processing},
keywords = {Basis pursuit,Block-sparsity,Compressed sensing,Matching pursuit},
mendeley-groups = {PhD - 1st Year/compressed sensing/Block Sparsity},
number = {6},
pages = {3042--3054},
title = {{Block-sparse signals: Uncertainty relations and efficient recovery}},
volume = {58},
year = {2010}
}

@article{Stojnic2009,
abstract = {Let A be an M by N(M > N) which is an instance of a real random Gaussian ensemble. In compressed sensing we are interested in finding the sparsest solution to the system of equations Ax = y for a given y. In general, whenever the sparsity of x is smaller than half the dimension of y then with overwhelming probability over A the sparsest solution is unique and can be found by an exhaustive search over x with an exponential time complexity for any y. The recent work of Cand{\'{e}}s, Donoho, and Tao shows that minimization of the ℓ1 norm of x subject to A x = y results in the sparsest solution provided the sparsity of x, say K, is smaller than a certain threshold for a given number of measurements. Specifically, if the dimension of y approaches the dimension of x, the sparsity of x should be K ≫ 0.239 N. Here, we consider the case where x is block sparse, i.e., x consists of n = N/d blocks where each block is of length d and is either a zero vector or a nonzero vector (under nonzero vector we consider a vector that can have both, zero and nonzero components). Instead of ℓ1-norm relaxation, we consider the following relaxation: min ∥ X1 ∥2 + ∥X2∥2 + ⋯ + ∥ Xn ∥2, subject to A x = y (*) where Xi = (x(i-1)d+1,x (i-1)d+2, ⋯ xid) T i = 1,2, ⋯ N. Our main result is that as n → ∞, (z.ast;) finds the sparsest solution to A x = y, with overwhelming probability in A, for any x whose sparsity is k/n < (1/2) - O($\epsilon$), provided m/n > 1 - 1/d, and d = $\Omega$(log(1/$\epsilon$)/ $\epsilon$ 3. The relaxation given in (z.ast;) can be solved in polynomial time using semi-definite programming. {\textcopyright} 2009 IEEE.},
archivePrefix = {arXiv},
arxivId = {0804.0041},
author = {Stojnic, Mihailo and Parvaresh, Farzad and Hassibi, Babak},
doi = {10.1109/TSP.2009.2020754},
eprint = {0804.0041},
file = {:D\:/Mendeley Working Foler/IEEE Transactions on Signal Processing/2009/Stojnic, Parvaresh, Hassibi - 2009 - On the reconstruction of block-sparse signals with an optimal number of measurements.pdf:pdf},
issn = {1053587X},
journal = {IEEE Transactions on Signal Processing},
keywords = {Block-sparse signals,Compressed sensing,Semi-definite programming},
mendeley-groups = {PhD - 1st Year/compressed sensing/Block Sparsity},
number = {8},
pages = {3075--3085},
title = {{On the reconstruction of block-sparse signals with an optimal number of measurements}},
volume = {57},
year = {2009}
}
@article{Parvaresh2008,
author = {Parvaresh, Farzad and Vikalo, Haris and Misra, Sidhant and Hassibi, Babak},
doi = {10.1109/JSTSP.2008.924384},
file = {:D\:/Mendeley Working Foler/IEEE Journal of Selected Topics in Signal Processing/2008/Parvaresh et al. - 2008 - Recovering Sparse Signals Using Sparse Measurement Matrices in Compressed DNA Microarrays.pdf:pdf},
issn = {1932-4553},
journal = {IEEE Journal of Selected Topics in Signal Processing},
mendeley-groups = {PhD - 1st Year/compressed sensing/Block Sparsity},
month = {jun},
number = {3},
pages = {275--285},
title = {{Recovering Sparse Signals Using Sparse Measurement Matrices in Compressed DNA Microarrays}},
url = {http://ieeexplore.ieee.org/document/4550564/},
volume = {2},
year = {2008}
}

@article{Zhang2011,
abstract = {—This paper proposes an extended reference current calculation method for the PV based three-level neutral point clamped (NPC) shunt active power filter (SAPF). Shunt active power filter demands a source of energy for compensating the current based distortions, which utilizes the photovoltaic array with DC-DC boost converter as a source of DC power. The shunt connected inverter controls the DC link voltage as well as the active and reactive power transferred between the renewable energy sources to grid with improved power quality. The proposed controller is based on the use of high selectivity filter (HSF) for reference current generations. In addition the fuzzy logic controller is implemented for better current control accuracy of shunt active filter. The main benefits of the proposed system are that it will provide uninterrupted compensation for the whole day and compensate the voltage interruption. This system utilizes the renewable energy and accordingly saves the energy, shares the load and provides uninterruptable power supply to critical/sensitive load, through the photovoltaic (PV) array/battery bank during the day and night. A simulation of the proposed topology has been carried out in the MATLAB/Simulink environment and the results are presented. Experimental studies are carried out to confirm the effectiveness of the proposed configuration.  Index Terms—photovoltaic systems, DC-DC power converters, multi level NPC voltage source inverter, fuzzy control, total harmonic distortion},
author = {Zhang, Zhilin and Rao, Bhaskar D},
doi = {10.1109/JSTSP.2011.2159773},
file = {:D\:/Mendeley Working Foler/IEEE Journal of Selected Topics in Signal Processing/2011/Zhang, Rao - 2011 - Source Vectors Using Sparse Bayesian Learning.pdf:pdf},
issn = {1932-4553},
journal = {IEEE Journal of Selected Topics in Signal Processing},
mendeley-groups = {PhD - 1st Year/compressed sensing/Block Sparsity},
month = {sep},
number = {5},
pages = {912--926},
publisher = {IEEE},
title = {{Sparse Signal Recovery With Temporally Correlated Source Vectors Using Sparse Bayesian Learning}},
url = {http://ieeexplore.ieee.org/document/5887383/},
volume = {5},
year = {2011}
}

@article{Zhang2013,
	abstract = {We examine the recovery of block sparse signals and extend the recovery framework in two important directions; one by exploiting the signals' intra-block correlation and the other by generalizing the signals' block structure. We propose two families of algorithms based on the framework of block sparse Bayesian learning (BSBL). One family, directly derived from the BSBL framework, require knowledge of the block structure. Another family, derived from an expanded BSBL framework, are based on a weaker assumption on the block structure, and can be used when the block structure is completely unknown. Using these algorithms, we show that exploiting intra-block correlation is very helpful in improving recovery performance. These algorithms also shed light on how to modify existing algorithms or design new ones to exploit such correlation and improve performance. {\textcopyright} 1991-2012 IEEE.},
	archivePrefix = {arXiv},
	arxivId = {1201.0862},
	author = {Zhang, Zhilin and Rao, Bhaskar D},
	doi = {10.1109/TSP.2013.2241055},
	eprint = {1201.0862},
	file = {:D$\backslash$:/Mendeley Working File/IEEE Transactions on Signal Processing/2013/Zhang, Rao - Extension of SBL algorithms for the recovery of block sparse signals with intra-block correlation - 2013.pdf:pdf},
	issn = {1053587X},
	journal = {IEEE Transactions on Signal Processing},
	keywords = {Block sparse model,compressed sensing,intra-block correlation,sparse Bayesian learning (SBL),sparse signal recovery},
	mendeley-groups = {PhD - 1st Year/compressed sensing/Block Sparsity},
	number = {8},
	pages = {2009--2015},
	publisher = {IEEE},
	title = {{Extension of SBL algorithms for the recovery of block sparse signals with intra-block correlation}},
	volume = {61},
	year = {2013}
}

@article{Tropp2006_2,
	abstract = {A simultaneous sparse approximation problem requests a good approximation of several input signals at once using different linear combinations of the same elementary signals. At the same time, the problem balances the error in approximation against the total number of elementary signals that participate. These elementary signals typically model coherent structures in the input signals, and they are chosen from a large, linearly dependent collection. The first part of this paper presents theoretical and numerical results for a greedy pursuit algorithm, called simultaneous orthogonal matching pursuit. The second part of the paper develops another algorithmic approach called convex relaxation. This method replaces the combinatorial simultaneous sparse approximation problem with a closely related convex program that can be solved efficiently with standard mathematical programming software. The paper develops conditions under which convex relaxation computes good solutions to simultaneous sparse approximation problems. {\textcopyright} 2005 Elsevier B.V. All rights reserved.},
	author = {Tropp, Joel A.},
	doi = {10.1016/j.sigpro.2005.05.031},
	file = {:D$\backslash$:/Mendeley Working File/Signal Processing/2006/Tropp - Algorithms for simultaneous sparse approximation. Part II Convex relaxation - 2006.pdf:pdf},
	issn = {01651684},
	journal = {Signal Processing},
	keywords = {Combinatorial optimization,Convex relaxation,Multiple measurement vectors,Simultaneous sparse approximation},
	mendeley-groups = {PhD - 1st Year/compressed sensing/MMV},
	number = {3},
	pages = {589--602},
	title = {{Algorithms for simultaneous sparse approximation. Part II: Convex relaxation}},
	volume = {86},
	year = {2006}
}
@article{Tropp2006,
	author = {Tropp, JA and Gilbert, A and Strauss, M},
	file = {:D$\backslash$:/Mendeley Working File/Signal Processing/2006/Tropp, Gilbert, Strauss - Algorithms for simultaneous sparse approximation. Part I Greedy pursuit - 2006.pdf:pdf},
	journal = {Signal Processing},
	keywords = {2074 east hall,and phrases,ann arbor,annacg,at the department,edu or by post,greedy algorithms,jtropp,martinjs,mi 48109-1109,multiple measurement vectors,of mathematics,orthogonal matching pursuit,reached by e-mail at,simul-,subset selection,taneous sparse approximation,the authors may be,the university of michigan,umich},
	mendeley-groups = {PhD - 1st Year/compressed sensing/MMV},
	pages = {1--21},
	title = {{Algorithms for simultaneous sparse approximation. Part I: Greedy pursuit}},
	url = {http://www.sciencedirect.com/science/article/pii/S0165168405002227},
	year = {2006}
}